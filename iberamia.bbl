\begin{thebibliography}{10}

\bibitem{Hutter}
50'000 prize for compressing human knowledge.
\newblock \url{ http://prize.hutter1.net/}.

\bibitem{Bown}
Oliver Bown and Sebastian Lexer.
\newblock Continuous-time recurrent neural networks for generative and
  interactive musical performance.
\newblock In {\em Rothlauf F. et al. (eds) Applications of Evolutionary
  Computing. EvoWorkshops 2006}, volume 3907, pages 652--663, Springer, Berlin,
  Heidelberg.

\bibitem{Celikel}
Ebru Celikel and Mehmet~Emin Dalkilic.
\newblock Investigating the effects of recency and size of training text on
  author recognition problem.
\newblock In {\em Computer and Information Sciences - ISCIS 2004}, volume 3280,
  pages 21--30, Springer.

\bibitem{Chierichetti}
Flavio Chierichetti, Ravi Kumar, Sandeep Pandey, and Sergei Vassilvitskii.
\newblock Finding the jaccard median.
\newblock \url{ http://theory.stanford.edu/~sergei/papers/soda10-jaccard.pdf}.

\bibitem{Cilibrasi}
Rudi Cilibrasi and Paul Vitanyi.
\newblock Clustering by compression.
\newblock {\em IEEE Transactions on Information Theory}, 51:1523--1545, April
  2005.

\bibitem{Ofir}
Ofir David, Shay Moran, and Amir Yehudayoff.
\newblock On statistical learning via the lens of compression.
\newblock \url{ https://arxiv.org/pdf/1610.03592.pdf}, October 2016.
\newblock arXiv:1610.03592v2.

\bibitem{Franz}
Arthur Franz.
\newblock Artificial general intelligence through recursive data compression
  and grounded reasoning: a position paper.
\newblock \url{ https://arxiv.org/pdf/1506.04366.pdf}, June 2015.
\newblock arXiv:1506.04366v1.

\bibitem{Gers}
Felix Gers, Jürgen Schmidhuber, and Fred Cummins.
\newblock Learning to forget: Continual prediction with lstm.
\newblock \url{
  https://pdfs.semanticscholar.org/1154/0131eae85b2e11d53df7f1360eeb6476e7f4.pdf},
  January 1999.

\bibitem{Variation}
Alison~L. Gibbs and Francis~Edward Su.
\newblock On choosing and bounding probability metrics.
\newblock {\em International Statistical Review}, 70:419--435, September 2002.

\bibitem{Graves2}
Alex Graves.
\newblock {\em Supervised Sequence Labelling with Recurrent Neural Networks},
  volume 385.
\newblock Springer, 2012.

\bibitem{Graves}
Alex Graves.
\newblock Generating sequences with recurrent neural networks.
\newblock \url{https://arxiv.org/pdf/1308.0850.pdf}, June 2014.
\newblock arXiv:1308.0850v5.

\bibitem{Gregor}
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo~Jimenez Rezende, and Daan
  Wierstra.
\newblock Draw: A recurrent neural network for image generation.
\newblock \url{ https://arxiv.org/pdf/1502.04623.pdf}, February 2015.
\newblock arXiv:1502.04623v2.

\bibitem{Grunwald}
Peter Grunwald.
\newblock A tutorial introduction to the minimum description length principle.
\newblock \url{ https://arxiv.org/pdf/math/0406077.pdf}, June 2004.
\newblock arXiv:math/0406077v1.

\bibitem{Karpathy}
Andrej Karpathy.
\newblock The unreasonable effectiveness of recurrent neural networks.
\newblock \url{ http://karpathy.github.io/2015/05/21/rnn-effectiveness/}, May
  2015.

\bibitem{Vitanyi}
Ming Li and Paul Vitanyi.
\newblock {\em An Introduction to Kolmogorov Complexity and Its Applications}.
\newblock Springer, 2008.

\bibitem{Maas}
Andrew Maas, Raymond Daly, Peter Pham, Dan Huang, Andrew Ng, and Christopher
  Potts.
\newblock Learning word vectors for sentiment analysis.
\newblock \url{
  http://ai.stanford.edu/~ang/papers/acl11-WordVectorsSentimentAnalysis.pdf}.

\bibitem{Matt3}
Matt Mahoney.
\newblock Fast text compression with neural networks.
\newblock \url{ https://cs.fit.edu/~mmahoney/compression/mmahoney00.pdf}.

\bibitem{Mahoney}
Matt Mahoney.
\newblock The paq data compression series.
\newblock \url{ http://mattmahoney.net/dc/paq.html}.

\bibitem{Mahoney2}
Matt Mahoney.
\newblock Adaptive weighing of context models for lossless data compression.
\newblock \url{ https://cs.fit.edu/~mmahoney/compression/cs200516.pdf}, 2005.

\bibitem{Mahoney4}
Matt Mahoney.
\newblock Data compression explained.
\newblock \url{ http://mattmahoney.net/dc/dce.html#Section_4}, April 2013.

\bibitem{Ratsaby}
Joel Ratsaby.
\newblock Prediction by compression.
\newblock \url{ https://arxiv.org/pdf/1008.5078.pdf}, August 2010.
\newblock arXiv:1008.5078v1.

\bibitem{Schmidhuber}
Jürgen Schmidhuber and Stefan Heil.
\newblock Sequential neural text compression.
\newblock {\em IEEE Transactions on Neural Networks}, 7:142--146, January 1996.

\bibitem{Socher}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher Manning,
  Andrew Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock \url{ https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf}, 2013.

\bibitem{InverseSampling}
Mark Steyvers.
\newblock {\em Computational Statistics with Matlab}.
\newblock May 2011.

\bibitem{Sutskever}
Ilya Sutskever, James Martens, and Geoffrey Hinton.
\newblock Generating text with recurrent neural networks.
\newblock \url{ http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf}, 2011.

\bibitem{Ziegelmayer}
Dominique Ziegelmayer and Rainer Schrader.
\newblock Sentiment polarity classification using statistical data compression
  models.
\newblock {\em IEEE 12th International Conference on}, December 2012.

\end{thebibliography}
