\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Graves}
\citation{Sutskever}
\citation{Bown}
\citation{Graves}
\citation{Sutskever}
\citation{Cilibrasi}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{123}{section.1}}
\citation{Franz}
\citation{Ofir}
\citation{Ratsaby}
\citation{Grunwald}
\citation{Gers}
\citation{Schmidhuber}
\citation{Sutskever}
\citation{Bown}
\citation{Gregor}
\citation{Schmidhuber}
\citation{Socher}
\citation{Mahoney}
\citation{Mahoney}
\citation{Maas}
\citation{Vitanyi}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data Compression as an Artificial Intelligence Field}{124}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}RNNs for Data Compression}{124}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Sentiment Analysis}{124}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}A Qualitative Approach}{124}{subsection.4.1}}
\citation{Maas}
\citation{Ziegelmayer}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Data Set Preparation}{125}{subsection.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Movie review dataset.}}{125}{table.1}}
\newlabel{tab:sample}{{1}{125}{Movie review dataset}{table.1}{}}
\citation{Hutter}
\citation{Mahoney}
\citation{Socher}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}PAQ for Sentiment Analysis}{126}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Experiment Results}{126}{subsection.4.4}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces PAQ vs RNN Classification Results.}}{126}{table.2}}
\newlabel{tab:sample}{{2}{126}{PAQ vs RNN Classification Results}{table.2}{}}
\citation{Karpathy}
\citation{Mahoney4}
\citation{Matt3}
\citation{InverseSampling}
\citation{pearl1984}
\citation{hartetal1968}
\citation{korf1985}
\citation{oetikeretal2008}
\citation{vovk2007}
\citation{oetikeretal2008}
\@writefile{toc}{\contentsline {section}{\numberline {5}Automatic Text Generation}{127}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Data Model}{127}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Text Generation}{127}{subsection.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6}References}{127}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}What is a DOI?}{128}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Where can I find the DOI of my references?}{128}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Why is it important to include DOI numbers in references (when available)?}{128}{subsection.6.3}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Journal Scope}{128}{section.7}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Manuscript Submission and Review}{128}{section.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces PAQ splits the [0,1) interval giving $1/4$ of probability to bit 0 and $3/4$ of probability to bit 1. When a random number is sampled in this context it is more likely to generate a 1. Each generated bit updates all models' context. However, that bit should not be learned becaused of its random nature. In other words, PAQ just learns from the training set and then generates random text using that probabilistic model. After 8 bits, a character is generated.}}{128}{figure.1}}
\newlabel{fig1}{{1}{128}{PAQ splits the [0,1) interval giving $1/4$ of probability to bit 0 and $3/4$ of probability to bit 1. When a random number is sampled in this context it is more likely to generate a 1. Each generated bit updates all models' context. However, that bit should not be learned becaused of its random nature. In other words, PAQ just learns from the training set and then generates random text using that probabilistic model. After 8 bits, a character is generated}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces DOI in a printed document.}}{129}{figure.2}}
\newlabel{fig:print-doi}{{2}{129}{DOI in a printed document}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces DOI in a document available on the Web.}}{129}{figure.3}}
\newlabel{fig:home-doi}{{3}{129}{DOI in a document available on the Web}{figure.3}{}}
\bibstyle{plain}
\bibdata{References}
\bibcite{Hutter}{1}
\bibcite{Bown}{2}
\bibcite{Cilibrasi}{3}
\bibcite{Ofir}{4}
\@writefile{toc}{\contentsline {section}{\numberline {9}Originality and Copyright}{130}{section.9}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Monographs and Special Issues}{130}{section.10}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Theses Summaries }{130}{section.11}}
\bibcite{Franz}{5}
\bibcite{Gers}{6}
\bibcite{Graves}{7}
\bibcite{Gregor}{8}
\bibcite{Grunwald}{9}
\bibcite{Karpathy}{10}
\bibcite{Vitanyi}{11}
\bibcite{Maas}{12}
\bibcite{Matt3}{13}
\bibcite{Mahoney}{14}
\bibcite{Mahoney4}{15}
\bibcite{Ratsaby}{16}
\bibcite{Schmidhuber}{17}
\bibcite{Socher}{18}
\bibcite{InverseSampling}{19}
\bibcite{Sutskever}{20}
\bibcite{Ziegelmayer}{21}
\newlabel{LastPage}{{}{131}{}{page.131}{}}
